---
title: "OHI `r format(Sys.Date(), '%Y')` - tidal flat extent"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../workflow/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---

# Summary

This script generates the extent of tidal flat extent for each OHI region. 


## Updates from previous assessment

2022 - Completely new!

***
## Data Source 

**Reference**: Murray, N.J., Phinn, S.R., DeWitt, M., Ferrari, R., Johnston, R., Lyons, M.B., Clinton, N., Thau, D. & Fuller, R.A. (2019) The global distribution and trajectory of tidal flats. Nature, 565, 222-225.

**Downloaded**: 2022-07-26

**Description**:  
The Murray Global Intertidal Change Dataset contains global maps of tidal flat ecosystems produced via a supervised classification of 707,528 Landsat Archive images. Each pixel was classified into tidal flat, permanent water or other with reference to a globally distributed set of training data.

The classification was implemented along the entire global coastline between 60° North and 60° South from 1 January 1984 to 31 December 2016. The image collection consists consists of a time-series of 11 global maps of tidal flats at 30m pixel resolution for set time-periods (1984−1986; 1987−1989; 1990−1992; 1993−1995; 1996−1998; 1999−2001; 2002−2004; 2005−2007; 2008−2010; 2011−2013; 2014−2016)

This product depicts tidal flat ecosystems around the global coastline.

Pixels classified as tidal flat in the analysis represent several types of tidal flat ecosystems, including unconsolidated fine-grain sediments (tidal mudflats), unconsolidated coarse-grain sediments (tidal sand flats), and consolidated sediments, organic material or rocks (wide tidal rock-platforms), while excluding spectral signatures indicating the presence of vegetation dominated intertidal ecosystems such as mangroves and vegetated marshes. The analysis aimed to identify pixels that are subject to regular tidal inundation, and therefore may also include other intertidal systems where intertidal dynamics are observable.

**Time range**: 1984-2016

**Download link**: https://www.intertidal.app/download/direct-download (use the provided shell script in this file)

**Variables**:

- classification	occurrence: intertertidal area classification for the interval.

  - 0 is not tidal flat
  - 1 is tidal flat

- raster shards use geodetic extent in the file names

***

# Methods

## Overview

IDK lol

## Setup

``` {r setup, eval = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, eval = FALSE, echo = TRUE)

if (!require(librarian)){install.packages("librarian")}

librarian::shelf(
  tidyverse,
  here,
  janitor,
  plotly,
  sf,
  fasterize,
  terra,
  raster,
  tictoc,
  foreach,
  doParallel
) 
### directory paths and relevant files
current_year <- 2022
version_year <- paste0("v", current_year)
data_year <- paste0("d", current_year)

source(here::here('workflow', 'R', 'common.R'))

### Mazu
dir_here  <- here::here('globalprep', 'hab_saltmarsh', version_year)
dir_data <- file.path(dir_M, 'git-annex', 'globalprep', '_raw_data', 'global_tidal_wetland_change', data_year)

### Aurora
# dir_here <- file.path('/home/shares/food-systems/Global_datasets/global_tidal_wetland_change')
# dir_data <- file.path('/home/shares/food-systems/Global_datasets/global_tidal_wetland_change/d2022')
```

### Download the data

The following bash script will download the raw data for the tidal wetland change dataset. 

```{bash eval = FALSE}
### Make the new directory and move into it
mkdir /home/shares/ohi/git-annex/globalprep/_raw_data/global_tidal_wetland_change/d2022/raw/tidal_flats && cd $_

### Declare an array of strings
declare -a StringArray=(
  "1984-1986" 
  "1987-1989" 
  "1990-1992" 
  "1993-1995" 
  "1996-1998" 
  "1999-2001" 
  "2002-2004" 
  "2005-2007" 
  "2008-2010" 
  "2011-2013"
  "2014-2016"
)
### Iterate the string array using for loop
for val in ${StringArray[@]}; do
  echo $val
  wget https://storage.googleapis.com/uq-intertidal/v1_1/global_intertidal/$val.zip
  unzip $val.zip -d ./$val
  rm $val.zip
done

### Make down_sample folde with subfolders
mkdir ../../int/tidal_flat_down_sample && cd $_
### Iterate the string array using for loop
for val in ${StringArray[@]}; do
  echo $val
  mkdir $val
done

### Make mosaic folde with subfolders
mkdir /home/shares/ohi/git-annex/globalprep/_raw_data/global_tidal_wetland_change/d2022/int/tidal_flat_mosaic && cd $_
### Iterate the string array using for loop
for val in ${StringArray[@]}; do
  echo $val
  mkdir $val
done
```

## Down sample rasters

Down sample rasters from 30 m$^2$ ground sample distance (GSD) to ~ 1 km$^2$ GSD

- 30 pixels is 900 m$^2$
  - (900*900)/1000000 = 0.81 km$^2$
- file size is reduced from 27-57 MB per shard to about 340 KB per shard
- take the sum of the pixels
- convert to area (multiply sum of pixels by 0.0009)
  - If the native raster cells are 30x30 m$^2$ area, then a raster cell with a value of 1 would be equivalent to 0.0009 km$^2$ habitat area: (30*30)/(1000*1000) = 0.0009
- write new `.tif` files into `int/down_sample` folder

```{r eval = FALSE}
tictoc::tic()

registerDoParallel(11)

scale_factor = 30

folders <- list.files(paste0(dir_data, "/raw/tidal_flats"))

foreach (dir = folders) %dopar% { 
  
  files <- list.files(paste0(dir_data, "/raw/tidal_flats/", dir))
  
  for (file in files){
    
    fn <- file %>% 
      stringr::str_replace(pattern     = ".tif",
                           replacement = "_down_sampled.tif") 
    
    file_name <- paste0(dir_data, "/int/tidal_flat_down_sample/", dir, "/", fn)
    
    if(!file.exists(file_name)){
      
      img <- terra::rast(paste0(dir_data, "/raw/tidal_flats/", dir, "/", file)) 
      
      down_sampled_img <- terra::aggregate(
        x = img, 
        fact = scale_factor, 
        fun = sum,
        na.rm = T
      )
      
      sum_to_area_img <- down_sampled_img * 0.0009

      terra::writeRaster(sum_to_area_img, filename = file_name)
      
    } else {
      cat(paste0(fn, " already exists!\n"))
    }
  }
}
tictoc::toc()
```

## Mosaic the rasters

This step usually fails if you try to do all of the raster. Here we break it up into two steps. 

- 1 global raster per year for with gain-loss difference at 1 km$^2$ resolution
- `terra::mosaic()` is still crashing my R session at this resolution so need to look into a better way to do this
- write new `.tif` files into `int/output` folder

### Step 1

The first step takes the 147 files per group and breaks them into 7 parts (21 images each), and mosaics those parts together.

```{r}
tictoc::tic()

registerDoParallel(3)

folders <- list.files(paste0(dir_data, "/int/tidal_flat_down_sample"))

foreach (dir = folders) %dopar% { 
  
  files <- list.files(paste0(dir_data, "/raw/tidal_flats/", dir), full.names = T)
  
  for (part in 1:9) {
    
    files_chunk = files[(12*part-11):(12*part)]
    
    file_name <- paste0(dir_data, "/int/tidal_flat_mosaic/", dir, "/", part, "_mosaic.tif")
    
    if(!file.exists(file_name)){
      
      img_rast_agg <- terra::sprc(lapply(files_chunk, terra::rast))
      
      raster_mos <- terra::merge(
        img_rast_agg,
        filename = file_name
      )
      
    } else {cat(paste0(file_name, " already exists!\n"))}
  }
}
tictoc::toc()
```

```{r eval = FALSE}
tictoc::tic()

registerDoParallel(6)

loss_files <- list.files(paste0(dir_data, "/int/down_sample"), pattern = "loss_in_")
gain_files <- list.files(paste0(dir_data, "/int/down_sample"), pattern = "gain_in_")

years <- c(4, 7, 10, 13, 16, 19)

foreach (yr = years) %dopar% {
  
  yr_loss_files <- grep(paste0("_", yr, "_"), loss_files, value = TRUE)
  yr_gain_files <- grep(paste0("_", yr, "_"), gain_files, value = TRUE)
  
  for (part in 1:9) {
    
    yr_loss_files_chunk = yr_loss_files[(12*part-11):(12*part)]
    
    fn_loss <- yr_loss_files_chunk %>%
      stringr::str_replace(
        pattern = paste0("murray-gic-v1.0.1-loss_in_", yr, "_"),
        replacement = paste0("loss_in_", yr, "_part_", part, "_"))

    file_name_loss <- paste0(dir_data, "/int/partial_mosaic/", fn_loss[1])
    
    if(!file.exists(file_name_loss)){
      
      img_rast_agg <- sprc(lapply(paste0(dir_data, "/int/down_sample/", yr_loss_files_chunk), terra::rast))
      
      raster_mos <- terra::merge(
        img_rast_agg,
        filename = file_name_loss
      )
    } else {cat(paste0(fn_loss[1], " already exists!\n"))}
    
    
    yr_gain_files_chunk = yr_gain_files[(7*part-6):(7*part)]
    
    fn_gain <- yr_gain_files_chunk %>%
      stringr::str_replace(
        pattern = paste0("murray-gic-v1.0.1-gain_in_", yr, "_"),
        replacement = paste0("gain_in_", yr, "_part_", part, "_"))

    file_name_gain <- paste0(dir_data, "/int/partial_mosaic/", fn_gain[1])
    
    if(!file.exists(file_name_gain)){
      
      img_rast_agg <- sprc(lapply(paste0(dir_data, "/int/down_sample/", yr_gain_files_chunk), terra::rast))
      
      raster_mos <- terra::merge(
        img_rast_agg,
        filename = file_name_gain
      )
    } else {cat(paste0(fn_gain[1], " already exists!\n"))}
  }
}

tictoc::toc()
```

### Step 2

The second step takes the 7 files per group and mosaics those parts together.

```{r eval = FALSE}
tictoc::tic()

registerDoParallel(3)

loss_files <- list.files(paste0(dir_data, "/int/partial_mosaic"), pattern = "loss_in_")
gain_files <- list.files(paste0(dir_data, "/int/partial_mosaic"), pattern = "gain_in_")

years <- c(4, 7, 10, 13, 16, 19)

foreach (yr = years) %dopar% {
  
  yr_loss_files <- grep(paste0("in_", yr, "_"), loss_files, value = TRUE)
  yr_gain_files <- grep(paste0("in_", yr, "_"), gain_files, value = TRUE)
  
  fn_loss <- yr_loss_files %>%
    stringr::str_replace(
      pattern = paste0("_part_[:digit:]_down_sampled_\\d+-\\d+.tif"),
      replacement = "_global.tif")
  
  file_name_loss <- paste0(dir_data, "/output/", fn_loss[1])
  
  if(!file.exists(file_name_loss)){
    
    spat_raster_collection <- sprc(lapply(paste0(dir_data, "/int/partial_mosaic/", yr_loss_files), terra::rast))
    
    raster_mosaic <- terra::merge(
      spat_raster_collection,
      filename = file_name_loss
    )
  } else {cat(paste0(fn_loss[1], " already exists!\n"))}
  
  fn_gain <- yr_gain_files %>%
    stringr::str_replace(
      pattern = paste0("_part_[:digit:]_down_sampled_\\d+-\\d+.tif"),
      replacement = "_global.tif")
  
  file_name_gain <- paste0(dir_data, "/output/", fn_gain[1])
  
  if(!file.exists(file_name_gain)){
    
    spat_raster_collection <- sprc(lapply(paste0(dir_data, "/int/partial_mosaic/", yr_gain_files), terra::rast))
    
    raster_mosaic <- terra::merge(
      spat_raster_collection,
      filename = file_name_gain
    )
  } else {cat(paste0(fn_gain[1], " already exists!\n"))}
  
}

tictoc::toc()
```

## Summarize the grid cells within each country

- Take the sum of the cells in each country for each year for gain and loss

```{r eval = FALSE}
### call the region shape file to import regions
regions_shape()

### filter for only eez shapes and land shapes
### we want both to ensure all of the intertidal zone is captured
regions_eez_and_land <- regions %>%
  dplyr::filter(rgn_type %in% c("eez", 'land')) %>% 
  sf::st_transform(crs = 4326)  

rgns <- ohicore::rgn_master %>% 
  dplyr::filter(rgn_typ == "eez") %>% 
  dplyr::select(rgn_id = rgn_id_2013, rgn_name = rgn_nam_2013) %>% 
  dplyr::distinct()

loss_files <- list.files(paste0(dir_data, "/output"), pattern = "loss_")
gain_files <- list.files(paste0(dir_data, "/output"), pattern = "gain_")

years <- c(4, 7, 10, 13, 16, 19)

registerDoParallel(2)

foreach (yr = years) %dopar% {
  ###### LOSS
  yr_loss_files <- grep(paste0("in_", yr, "_"), loss_files, value = TRUE)
  
  loss <- paste0(dir_data, "/output/", yr_loss_files)
  
  file_name_loss <- here::here(dir_here, "int", paste0("saltmarsh_loss_", yr, ".csv"))
  
  if(!file.exists(file_name_loss)){
    
    loss_image <- terra::rast(loss)
    
    loss_image[loss_image==0] <- NA
    
    loss_image_sf <- loss_image %>% 
      terra::as.points(na.rm = T) %>% 
      sf::st_as_sf()
    
    loss_country <- sf::st_intersection(loss_image_sf, regions_eez_and_land)
    
    loss_summary <- loss_country %>%
      as.data.frame() %>% 
      dplyr::group_by(rgn_id) %>% 
      dplyr::summarise(loss = sum(loss)) %>% 
      dplyr::left_join(rgns) %>% 
      readr::write_csv(file_name_loss)
  } else {cat(paste0(yr_loss_files, " already exists!\n"))}
  
  ###### GAIN
  yr_gain_files <- grep(paste0("in_", yr, "_"), gain_files, value = TRUE)
  
  gain <- paste0(dir_data, "/output/", yr_gain_files)
  
  file_name_gain <- here::here(dir_here, "int", paste0("saltmarsh_gain_", yr, ".csv"))
  
  if(!file.exists(file_name_gain)){ 
    
    gain_image <- terra::rast(gain)
    
    gain_image[gain_image==0] <- NA
    
    gain_image_sf <- gain_image %>% 
      terra::as.points(na.rm = T) %>% 
      sf::st_as_sf()
    
    gain_country <- sf::st_intersection(gain_image_sf, regions_eez_and_land)
    
    gain_summary <- gain_country %>%
      as.data.frame() %>% 
      dplyr::group_by(rgn_id) %>% 
      dplyr::summarise(gain = sum(gain)) %>% 
      dplyr::left_join(rgns) %>% 
      readr::write_csv(file_name_gain)
  } else {cat(paste0(yr_gain_files, " already exists!\n"))}

}
```

```{r eval = FALSE}
### Whoops, forgot to add year as a column above lol
loss_files <- list.files(paste0(dir_here, "/int"), pattern = "loss_")
gain_files <- list.files(paste0(dir_here, "/int"), pattern = "gain_")

years <- c(4, 7, 10, 13, 16, 19)

loss_output <- dplyr::tibble()
gain_output <- dplyr::tibble()

for (yr in years){
  ### LOSS
  yr_loss_files <- grep(paste0(yr), loss_files, value = TRUE)
  
  loss_tmp <- here::here(dir_here, 'int', yr_loss_files) %>% 
    readr::read_csv() %>% 
    dplyr::full_join(rgns) %>% 
    dplyr::mutate(loss = case_when(is.na(loss) ~ 0,T ~ loss),
                  year = 2000 + yr)
  
  loss_output <- rbind(loss_output, loss_tmp)
  
  ### GAIN
  yr_gain_files <- grep(paste0(yr), gain_files, value = TRUE)
  
  gain_tmp <- here::here(dir_here, 'int', yr_gain_files) %>% 
    readr::read_csv() %>% 
  dplyr::full_join(rgns) %>% 
  dplyr::mutate(gain = case_when(is.na(gain) ~ 0,T ~ gain),
                year = 2000 + yr)
  
  gain_output <- rbind(gain_output, gain_tmp)
}
```

## Subtract gain from loss

- gain - loss
- left with a difference for each country
- write the results as a `.csv` in the output directory
- left with a gain or loss for each country

```{r eval = FALSE}
gain_minus_loss <- gain_output %>% 
  dplyr::left_join(loss_output) %>% 
  dplyr::mutate(difference = gain - loss)

### extra for the curious
loss_summary <- gain_minus_loss %>% 
  dplyr::group_by(rgn_id, rgn_name) %>% 
  dplyr::summarise(loss = sum(loss))

gain_summary <- gain_minus_loss %>% 
  dplyr::group_by(rgn_id, rgn_name) %>% 
  dplyr::summarise(gain = sum(gain))

difference_summary <- gain_minus_loss %>% 
  dplyr::group_by(rgn_id, rgn_name) %>% 
  dplyr::summarise(difference = sum(difference))
```

## Write the results to output

```{r eval = FALSE}
gain_minus_loss %>% 
  dplyr::select(rgn_id, year, difference) %>% 
  readr::write_csv(here::here(dir_here, 'output', "saltmarsh_trend.csv"))
```

